{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFyb0y7PUJOo"
   },
   "source": [
    "# Iberdrola Project - Phase 2 [Occupancy Detection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9vTr2NhcGAA"
   },
   "source": [
    "# Test GPU (Optional)\n",
    "Before Starting, kindly check the available GPU from the Google Server, GPU model and other related information. It might help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled GPU Available? True\n",
      "GPU Number: 1\n",
      "Current GPU Index: 0\n",
      "GPU Type: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "GPU Capability: (8, 6)\n",
      "Is GPU Initialized yet? True\n",
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is CUDA enabled GPU Available?\", torch.cuda.is_available())\n",
    "print(\"GPU Number:\", torch.cuda.device_count())\n",
    "print(\"Current GPU Index:\", torch.cuda.current_device())\n",
    "print(\"GPU Type:\", torch.cuda.get_device_name(device=None))\n",
    "print(\"GPU Capability:\", torch.cuda.get_device_capability(device=None))\n",
    "print(\"Is GPU Initialized yet?\", torch.cuda.is_initialized())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgW7r0C9TuZk"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eMhBhz1CrMb3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import scipy\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat, savemat\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "03JA1kRfzoit"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data_occupancy', 'data_plugs', 'data_sm']>\n",
      "(78, 86400, 6)\n",
      "(78, 86400, 1)\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "fl_Data = h5py.File(os.path.join('Raw_Data/Phase_2_Exp_2/H03_Data_Matched_Occupancy.mat'), 'r')\n",
    "print(fl_Data.keys())\n",
    "# Extract\n",
    "X_Data = np.swapaxes(np.swapaxes(np.array(fl_Data['data_plugs']),0,1),1,2)\n",
    "Y_Data = np.expand_dims(np.array(fl_Data['data_occupancy']), axis=2)\n",
    "X_Data_shape = X_Data.shape\n",
    "Y_Data_shape = Y_Data.shape\n",
    "print(X_Data_shape)\n",
    "print(Y_Data_shape)\n",
    "sample_num = X_Data_shape[0]\n",
    "segment_length = X_Data_shape[1]\n",
    "num_channels = X_Data_shape[2]\n",
    "# Check for NaNs and InFs\n",
    "data = pd.Series(X_Data.ravel())\n",
    "print(data.isna().any())\n",
    "print(data.isin([np.inf, -np.inf]).any())\n",
    "data = pd.Series(Y_Data.ravel())\n",
    "print(data.isna().any())\n",
    "print(data.isin([np.inf, -np.inf]).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Raw Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 86400\n",
    "i = random.randint(0, X_Data_shape[0])\n",
    "plt.figure(figsize=(32,21))\n",
    "'''Freezer'''\n",
    "plt.subplot(7,1,1)\n",
    "plt.plot(X_Data[i,:,0], linewidth=3, label='Freezer GT', color='navy')\n",
    "plt.title(f\"House 03 - Freezer - Sample {i}\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "'''Kitchen Appliances'''\n",
    "plt.subplot(7,1,2)\n",
    "plt.plot(X_Data[i,:,1], linewidth=3, label='Kitchen Appliances GT', color='navy')\n",
    "plt.title(f\"Kitchen Appliances\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "'''PC and Router'''\n",
    "plt.subplot(7,1,3)\n",
    "plt.plot(X_Data[i,:,2], linewidth=3, label='PC and Router GT', color='navy')\n",
    "plt.title(f\"PC and Router\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "'''Fridge'''\n",
    "plt.subplot(7,1,4)\n",
    "plt.plot(X_Data[i,:,3], linewidth=3, label='Fridge GT', color='navy')\n",
    "plt.title(f\"Fridge\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "'''Kettle'''\n",
    "plt.subplot(7,1,5)\n",
    "plt.plot(X_Data[i,:,4], linewidth=3, label='Kettle GT', color='navy')\n",
    "plt.title(f\"Kettle\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.subplot(7,1,6)\n",
    "'''Entertainment'''\n",
    "plt.plot(X_Data[i,:,5], linewidth=3, label='Entertainment GT', color='navy')\n",
    "plt.title(f\"Entertainment\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "'''Occupancy Label'''\n",
    "plt.subplot(7,1,7)\n",
    "plt.plot(Y_Data[i,:,0], linewidth=3, label='Occupancy Label GT', color='navy')\n",
    "plt.title(f\"Occupancy Label\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pruning - Select channels with an acceptable number of datapoints (optional, for only multichannel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezer\n",
      "-0.003563348596562991\n",
      "Kitchen Appliances\n",
      "0.0015574774589559007\n",
      "PC and Router\n",
      "0.01144102586717364\n",
      "Fridge\n",
      "0.03104247876097299\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# data_current_channel_var = np.var(data_current_channel.ravel())\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data_current_channel_corr \u001b[38;5;241m<\u001b[39m thresh) \u001b[38;5;129;01mor\u001b[39;00m (i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdevice_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data_current_channel_corr)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "thresh = 0.05\n",
    "X_Data_Pruned = np.zeros((sample_num,segment_length,num_channels))\n",
    "device_list = ['Freezer','Kitchen Appliances','PC and Router','Fridge','Entertainment']\n",
    "counter = 0\n",
    "for i in range(0,num_channels):\n",
    "    data_current_channel = X_Data[:,:,i]\n",
    "    data_current_channel_corr, _ = stats.pearsonr(data_current_channel.ravel(), Y_Data.ravel())\n",
    "    # data_current_channel_var = np.var(data_current_channel.ravel())\n",
    "    if (data_current_channel_corr < thresh) or (i == 0) or (i == 3):\n",
    "        print(device_list[i])\n",
    "        print(data_current_channel_corr)\n",
    "        continue\n",
    "    else:\n",
    "        X_Data_Pruned[:,:,counter] = data_current_channel\n",
    "        counter = counter + 1\n",
    "X_Data_Pruned = X_Data_Pruned[:,:,0:counter]\n",
    "X_Data_Shape = X_Data_Pruned.shape\n",
    "num_channels = X_Data_Shape[2]\n",
    "print(X_Data_Pruned.shape)\n",
    "print(Y_Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 86400, 4)\n",
      "(78, 86400, 1)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "X_Data_Shape = X_Data_Pruned.shape\n",
    "sample_num = X_Data_Shape[0]\n",
    "segment_length = X_Data_Shape[1]\n",
    "num_channels = X_Data_Shape[2]\n",
    "X_Data_New = np.zeros((sample_num,segment_length,num_channels))\n",
    "# Step 1: Range Normalize Data based on [0 1] threshold\n",
    "counter = 0\n",
    "threshold1 = 0\n",
    "for i in range(0,sample_num):\n",
    "    X_Data_Temp = X_Data_Pruned[i,:,:]\n",
    "    for ii in range(0,num_channels):\n",
    "        X_Data_Temp_Ch = X_Data_Temp[:,ii]\n",
    "        for iii in range(0,segment_length):\n",
    "            X_Data_Temp_Ch_Point = X_Data_Temp_Ch[iii]\n",
    "            if X_Data_Temp_Ch_Point > threshold1:\n",
    "                X_Data_Temp_Ch_Point = 1\n",
    "            X_Data_New[counter,iii,ii] = X_Data_Temp_Ch_Point\n",
    "    counter = counter + 1\n",
    "X_Data_New = np.int_(X_Data_New[0:counter,:,:])\n",
    "print(X_Data_New.shape)\n",
    "print(Y_Data.shape)\n",
    "print(np.unique(X_Data_New))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 86400, 4)\n",
      "(78, 86400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Merge short pulses into longer one based on threshold duration\n",
    "X_Data_Shape = X_Data_New.shape\n",
    "sample_num = X_Data_Shape[0]\n",
    "segment_length = X_Data_Shape[1]\n",
    "num_channels = X_Data_Shape[2]\n",
    "counter = 0\n",
    "threshold2 = 3600\n",
    "for i in range(0,sample_num):\n",
    "    X_Data_Temp = X_Data_New[i,:,:]\n",
    "    for ii in range(0,num_channels):\n",
    "        X_Data_Temp_Ch = X_Data_Temp[:,ii]\n",
    "        if np.var(X_Data_Temp_Ch) > 0:\n",
    "            transition_points = []\n",
    "            for iii in range(1,segment_length):\n",
    "                X_Data_Temp_Ch_Previous_Point = X_Data_Temp_Ch[iii-1]\n",
    "                X_Data_Temp_Ch_Current_Point = X_Data_Temp_Ch[iii]\n",
    "                if X_Data_Temp_Ch_Previous_Point != X_Data_Temp_Ch_Current_Point:\n",
    "                    transition_points.append(iii)\n",
    "            # print(transition_points)\n",
    "            for iii in range(1,len(transition_points)):\n",
    "                if ((transition_points[iii-1]-300) >= 0) and ((transition_points[iii-1]+300) < segment_length):\n",
    "                    X_Data_Temp_Ch[transition_points[iii-1]-300:transition_points[iii-1]+300] = 1\n",
    "                elif ((transition_points[iii-1]-300) < 0) and ((transition_points[iii-1]+300) < segment_length):\n",
    "                    X_Data_Temp_Ch[0:transition_points[iii-1]+300] = 1\n",
    "                elif ((transition_points[iii-1]-300) >= 0) and ((transition_points[iii-1]+300) >= segment_length):\n",
    "                    X_Data_Temp_Ch[transition_points[iii-1]-300:segment_length] = 1\n",
    "                transition_interval = transition_points[iii] - transition_points[iii-1]\n",
    "                if transition_interval <= threshold2:\n",
    "                    X_Data_Temp_Ch[transition_points[iii-1]:transition_points[iii]] = 1\n",
    "        X_Data_New[counter,:,ii] = X_Data_Temp_Ch\n",
    "    counter = counter + 1\n",
    "X_Data_New = X_Data_New[0:counter,:,:]\n",
    "print(X_Data_New.shape)\n",
    "print(Y_Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 86400\n",
    "i = random.randint(0, X_Data_shape[0])\n",
    "plt.figure(figsize=(32,12))\n",
    "'''PC and Router'''\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(X_Data_New[i,:,0], linewidth=3, label='PC and Router GT', color='navy')\n",
    "plt.plot(X_Data[i,:,2], linewidth=3, label='PC and Router GT', color='red')\n",
    "plt.title(f\"House 03 - PC and Router - Sample {i}\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "'''Kettle'''\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(X_Data_New[i,:,1], linewidth=3, label='Kettle GT', color='navy')\n",
    "plt.plot(X_Data[i,:,4], linewidth=3, label='Kettle GT', color='red')\n",
    "plt.title(f\"Kettle\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.subplot(4,1,3)\n",
    "'''Entertainment'''\n",
    "plt.plot(X_Data_New[i,:,2], linewidth=3, label='Entertainment GT', color='navy')\n",
    "plt.plot(X_Data[i,:,5], linewidth=3, label='Entertainment GT', color='red')\n",
    "plt.title(f\"Entertainment\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "'''Occupancy Label'''\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(Y_Data[i,:,0], linewidth=3, label='Occupancy Label GT', color='navy')\n",
    "plt.title(f\"Occupancy Label\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 86400, 1)\n",
      "(78, 86400, 1)\n",
      "[0 1]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_Data_Shape = X_Data_New.shape\n",
    "Y_Data_Shape = Y_Data.shape\n",
    "sample_num = X_Data_Shape[0]\n",
    "segment_length = X_Data_Shape[1]\n",
    "num_channels = X_Data_Shape[2]\n",
    "X_Data_AGG = np.zeros((sample_num,segment_length,1))\n",
    "counter = 0\n",
    "for i in range(0,sample_num):\n",
    "    X_Data_Temp = X_Data_New[i,:,:]\n",
    "    X_Data_Temp = np.sum(X_Data_Temp, axis=1)\n",
    "    X_Data_Temp[X_Data_Temp > 0] = 1\n",
    "    X_Data_AGG[counter,:,0] = X_Data_Temp\n",
    "    counter = counter + 1\n",
    "X_Data_AGG = np.int_(X_Data_AGG[0:counter,:,:])\n",
    "print(X_Data_AGG.shape)\n",
    "print(Y_Data.shape)\n",
    "print(np.unique(X_Data_AGG))\n",
    "print(np.unique(Y_Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Aggregated Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 86400\n",
    "i = random.randint(0, X_Data_AGG.shape[0]-1)\n",
    "'''Dishwasher'''\n",
    "plt.figure(figsize=(32,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(X_Data_AGG[i,:,0], linewidth=3, label='Aggregated Data GT', color='navy')\n",
    "plt.title(f\"House 03 - Aggregated Appliance Data - Sample {i}\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "'''Occupancy Label'''\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(Y_Data[i,:,0], linewidth=3, label='Occupancy Label GT', color='navy')\n",
    "plt.title(f\"Occupancy Label\", fontdict={'fontsize': 22})\n",
    "plt.xlim((0,segment_length))\n",
    "# plt.ylim((0,1))\n",
    "plt.tick_params(labelsize=16, colors='k')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanse and Save House 03 data for the combined approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 86400, 1)\n",
      "(5, 86400, 1)\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Curate\n",
    "X_Data_Shape = X_Data_AGG.shape\n",
    "Y_Data_Shape = Y_Data.shape\n",
    "sample_num = X_Data_Shape[0]\n",
    "segment_length = X_Data_Shape[1]\n",
    "num_channels = X_Data_Shape[2]\n",
    "X_Data_Curated = np.zeros((sample_num,segment_length,num_channels))\n",
    "Y_Data_Curated = np.zeros((sample_num,segment_length,1))\n",
    "counter = 0\n",
    "for i in range(0,sample_num):\n",
    "    X_Data_Temp = X_Data_AGG[i,:,:]\n",
    "    Y_Data_Temp = Y_Data[i,:,:]\n",
    "    Y_Data_Temp_SUM = np.sum(Y_Data_Temp)\n",
    "    if (Y_Data_Temp_SUM < np.round(0.01*segment_length)) or (Y_Data_Temp_SUM > np.round(0.99*segment_length)):\n",
    "        continue\n",
    "    if (np.var(X_Data_Temp) > 0.0001):\n",
    "        X_Data_Curated[counter,:,:] = X_Data_Temp\n",
    "        Y_Data_Curated[counter,:,:] = Y_Data_Temp\n",
    "        counter = counter + 1\n",
    "X_Data_Curated = np.int_(X_Data_Curated[0:counter,:,:])\n",
    "Y_Data_Curated = np.int_(Y_Data_Curated[0:counter,:,:])\n",
    "print(X_Data_Curated.shape)\n",
    "print(Y_Data_Curated.shape)\n",
    "print(np.unique(X_Data_Curated))\n",
    "print(np.unique(Y_Data_Curated))\n",
    "# Save\n",
    "data_dic = {\"X_Data\": X_Data_Curated,\n",
    "            \"Y_Data\": Y_Data_Curated,\n",
    "            }\n",
    "savemat(\"Occupancy_Data_Curated_House_03.mat\", data_dic, format='5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Folds - Train and Test Sets - 20% for Test - 10% for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 86400, 1)\n",
      "(102, 86400, 1)\n",
      "(26, 86400, 1)\n",
      "(26, 86400, 1)\n",
      "(26, 86400, 1)\n",
      "(26, 86400, 1)\n"
     ]
    }
   ],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X_Data_AGG, Y_Data, test_size=0.2, random_state=0)\n",
    "X_Val = X_Test\n",
    "Y_Val = Y_Test\n",
    "print(X_Train.shape)\n",
    "print(Y_Train.shape)\n",
    "print(X_Test.shape)\n",
    "print(Y_Test.shape)\n",
    "print(X_Val.shape)\n",
    "print(Y_Val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 86400, 1)\n",
      "(102, 86400, 1)\n",
      "(8812800, 1)\n",
      "(8812800, 1)\n",
      "(1011, 86400, 1)\n",
      "(1011, 86400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Overlap\n",
    "X_Data_Shape = X_Train.shape\n",
    "Y_Data_Shape = Y_Train.shape\n",
    "segment_length = X_Data_Shape[1]\n",
    "num_channels = X_Data_Shape[2]\n",
    "print(X_Data_Shape)\n",
    "print(Y_Data_Shape)\n",
    "# Reshape Array\n",
    "X_Data_Reshaped = np.reshape(X_Train, (X_Data_Shape[0]*X_Data_Shape[1], num_channels))\n",
    "Y_Data_Reshaped = np.reshape(Y_Train, (Y_Data_Shape[0]*Y_Data_Shape[1], 1))\n",
    "X_Data_Reshaped_Shape = X_Data_Reshaped.shape\n",
    "Y_Data_Reshaped_Shape = Y_Data_Reshaped.shape\n",
    "print(X_Data_Reshaped_Shape)\n",
    "print(Y_Data_Reshaped_Shape)\n",
    "# Overlap\n",
    "overlap_ratio = 0.9\n",
    "offset_amount = np.int_(segment_length*(1 - overlap_ratio))\n",
    "X_Data_New = np.zeros((2000,segment_length,num_channels))\n",
    "Y_Data_New = np.zeros((2000,segment_length,1))\n",
    "num_segments_approx = np.int_(np.ceil(X_Data_Reshaped_Shape[0]/offset_amount))\n",
    "counter = 0\n",
    "for i in range(0,num_segments_approx):\n",
    "    if (i*offset_amount+segment_length) > X_Data_Reshaped_Shape[0]:\n",
    "        continue\n",
    "    X_Data_Temp = X_Data_Reshaped[i*offset_amount:i*offset_amount+segment_length,:]\n",
    "    X_Data_New[counter,:,:] = X_Data_Temp\n",
    "    Y_Data_Temp = Y_Data_Reshaped[i*offset_amount:i*offset_amount+segment_length,:]\n",
    "    Y_Data_New[counter,:,:] = Y_Data_Temp\n",
    "    counter = counter + 1\n",
    "X_Train_OVRL = X_Data_New[0:counter,:,:]\n",
    "Y_Train_OVRL = Y_Data_New[0:counter,:,:]\n",
    "print(X_Train_OVRL.shape)\n",
    "print(Y_Train_OVRL.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Labels for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels(X_Data_OVRL, Y_Data_OVRL, segment_length, num_channels):\n",
    "    X_Data_New = np.zeros((20000,num_channels,segment_length))\n",
    "    Y_Data_New = np.zeros((20000,1), dtype=int)\n",
    "    ## Raw Dataset\n",
    "    X_Data_Shape = X_Data_OVRL.shape\n",
    "    Y_Data_Shape = Y_Data_OVRL.shape\n",
    "    # Reshape Array\n",
    "    X_Data_Reshaped = np.reshape(X_Data_OVRL, (X_Data_Shape[0]*X_Data_Shape[1], num_channels))\n",
    "    Y_Data_Reshaped = np.reshape(Y_Data_OVRL, (Y_Data_Shape[0]*Y_Data_Shape[1], 1))\n",
    "    X_Data_Reshaped_Shape = X_Data_Reshaped.shape\n",
    "    Y_Data_Reshaped_Shape = Y_Data_Reshaped.shape\n",
    "    num_segments_approx = np.int_(np.ceil(X_Data_Reshaped_Shape[0]/segment_length))\n",
    "    counter = 0\n",
    "    for i in range(0,num_segments_approx):\n",
    "        if ((i+1)*segment_length) > X_Data_Reshaped_Shape[0]:\n",
    "            continue\n",
    "        X_Data_Temp = np.transpose(X_Data_Reshaped[i*segment_length:(i+1)*segment_length,:])\n",
    "        X_Data_Temp_Mean = np.mean(X_Data_Temp)\n",
    "        X_Data_Temp_VAR = np.var(X_Data_Temp)\n",
    "        X_Data_New[counter,:,:] = X_Data_Temp\n",
    "        Y_Data_Temp = Y_Data_Reshaped[i*segment_length:(i+1)*segment_length,:]\n",
    "        Y_Data_Temp_Mean = np.mean(Y_Data_Temp)\n",
    "        Y_Data_Temp_VAR = np.var(Y_Data_Temp)\n",
    "        Y_Data_Temp_SUM = np.sum(Y_Data_Temp)\n",
    "        if X_Data_Temp_VAR <= 0.001:\n",
    "            continue\n",
    "        # if Y_Data_Temp_VAR <= 0.001:\n",
    "            # continue\n",
    "        if (Y_Data_Temp_SUM < np.round(0.1*segment_length)) or (Y_Data_Temp_SUM > np.round(0.90*segment_length)):\n",
    "            continue\n",
    "        # if Y_Data_Temp_SUM == segment_length:\n",
    "            # continue\n",
    "        if Y_Data_Temp_Mean > 0.5:\n",
    "            Y_Label = 1\n",
    "        else:\n",
    "            Y_Label = 0\n",
    "        Y_Data_New[counter,:] = Y_Label\n",
    "        counter = counter + 1\n",
    "    X_Data_New = X_Data_New[0:counter,:,:]\n",
    "    Y_Data_New = Y_Data_New[0:counter,:]\n",
    "    return X_Data_New, Y_Data_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(849, 1, 1200)\n",
      "(849, 1)\n",
      "(26, 1, 1200)\n",
      "(26, 1)\n",
      "(26, 1, 1200)\n",
      "(26, 1)\n",
      "[0 1] [379 470]\n",
      "[0 1] [12 14]\n",
      "[0 1] [12 14]\n"
     ]
    }
   ],
   "source": [
    "segment_length = 1200  # 20 Minutes = 1200 Data Points (1 Hz sampling rate)\n",
    "X_Train_C, Y_Train_C = transform_labels(X_Train_OVRL, Y_Train_OVRL, segment_length, num_channels)\n",
    "X_Test_C, Y_Test_C = transform_labels(X_Test, Y_Test, segment_length, num_channels)\n",
    "X_Val_C, Y_Val_C = transform_labels(X_Test, Y_Test, segment_length, num_channels)\n",
    "print(X_Train_C.shape)\n",
    "print(Y_Train_C.shape)\n",
    "print(X_Test_C.shape)\n",
    "print(Y_Test_C.shape)\n",
    "print(X_Val_C.shape)\n",
    "print(Y_Val_C.shape)\n",
    "labels, counts = np.unique(Y_Train_C, return_counts=True)\n",
    "print(labels, counts)\n",
    "labels, counts = np.unique(Y_Test_C, return_counts=True)\n",
    "print(labels, counts)\n",
    "labels, counts = np.unique(Y_Val_C, return_counts=True)\n",
    "print(labels, counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance train set (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(974, 8, 1200)\n",
      "(974, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_Train_0_indices = np.where(Y_Train_C == 0)[0]\n",
    "X_Train_C_0 = np.take(X_Train_C, Y_Train_0_indices, axis=0)\n",
    "Y_Train_C_0 = np.take(Y_Train_C, Y_Train_0_indices, axis=0)\n",
    "Y_Train_1_indices = np.where(Y_Train_C == 1)[0]\n",
    "X_Train_C_1 = np.take(X_Train_C, Y_Train_1_indices, axis=0)\n",
    "Y_Train_C_1 = np.take(Y_Train_C, Y_Train_1_indices, axis=0)\n",
    "#\n",
    "Y_Train_C_0_shape = Y_Train_C_0.shape\n",
    "Y_Train_C_1_shape = Y_Train_C_1.shape\n",
    "Y_Train_C_shape = Y_Train_C.shape\n",
    "if Y_Train_C_1_shape[0] > Y_Train_C_0_shape[0]:\n",
    "    index = np.random.choice(Y_Train_C_1_shape[0], Y_Train_C_0_shape[0], replace=False)\n",
    "    X_Train_1 = X_Train_C_1[index]\n",
    "    Y_Train_1 = Y_Train_C_1[index]\n",
    "    X_Train = np.concatenate([X_Train_C_0, X_Train_1], axis=0)\n",
    "    Y_Train = np.concatenate([Y_Train_C_0, Y_Train_1], axis=0)\n",
    "elif Y_Train_C_0_shape[0] > Y_Train_C_1_shape[0]:\n",
    "    index = np.random.choice(Y_Train_C_0_shape[0], Y_Train_C_1_shape[0], replace=False)\n",
    "    X_Train_0 = X_Train_C_0[index]\n",
    "    Y_Train_0 = Y_Train_C_0[index]\n",
    "    X_Train = np.concatenate([X_Train_C_1, X_Train_0], axis=0)\n",
    "    Y_Train = np.concatenate([Y_Train_C_1, Y_Train_0], axis=0)\n",
    "#\n",
    "X_Train_C = X_Train\n",
    "Y_Train_C = Y_Train\n",
    "print(X_Train_C.shape)\n",
    "print(Y_Train_C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dic = {\"X_Train\": X_Train_C,\n",
    "                  \"Y_Train\": Y_Train_C,\n",
    "                  \"X_Test\": X_Test_C,\n",
    "                  \"Y_Test\": Y_Test_C,\n",
    "                  \"X_Val\": X_Test_C,\n",
    "                  \"Y_Val\": Y_Test_C,\n",
    "                  }\n",
    "savemat(\"Data/Data_Fold_1.mat\", train_data_dic, format='5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qTwozk_BS94"
   },
   "source": [
    "Garbage Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633010341331,
     "user": {
      "displayName": "Sakib Mahmud",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg8lG2uTygQr7y6fmQUo67XXUtrCVGaEakj_P33Ft8=s64",
      "userId": "03961007737707022852"
     },
     "user_tz": -180
    },
    "id": "ch2jmn3jKKiH",
    "outputId": "c9807e23-ff6c-428d-f6e3-4f5e6382e71d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc #Garbage Collector\n",
    "fl_Data = None\n",
    "X_Test = None\n",
    "X_Train = None\n",
    "X_Val = None\n",
    "Y_Test = None\n",
    "Y_Train = None\n",
    "Y_Val = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHq0FrX9iAsq"
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yozhkF-OJWu2"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Mai6ZRMeiFvA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file 'Config_Train.ini' created\n"
     ]
    }
   ],
   "source": [
    "# CREATE OBJECT\n",
    "config_file = configparser.ConfigParser()\n",
    "# ADD NEW SECTION AND SETTINGS\n",
    "config_file[\"TRAIN\"] = {\n",
    "    'parentdir': '',  # Root or Parent Directory\n",
    "    'datafile': 'Data',  # Folder containing the dataset\n",
    "    'val_size': 0.0,  # Validation percentage for splitting\n",
    "    'q_order': 3,  # q-order for the Self-ONN or Super-ONN Models\n",
    "    'batch_size': 2,  # Batch Size, Change to fit hardware\n",
    "    'lossType': 'SoftM_MSE',  # loss function: 'SoftM_CELoss' or 'SoftM_MSE' or 'MSE'\n",
    "    'optim_fc': 'Adam',  # 'Adam' or 'SGD'\n",
    "    'lr': 0.0005,  # learning rate\n",
    "    'stop_criteria': 'accuracy',  # Stopping criteria: 'loss' or 'accuracy'\n",
    "    'n_epochs': 500,  # number of training epochs\n",
    "    'epochs_patience': 6,\n",
    "    'lr_factor': 0.1,  # lr_factor, if val loss did not decrease for a number of epochs (epochs_patience) then decrease learning rate by a factor of lr_factor\n",
    "    'max_epochs_stop': 30,  # maximum number of epochs with no improvement in validation loss for early stopping\n",
    "    'num_folds': 1,  # number of cross validation folds\n",
    "    'load_model': False,  # load model: True or False\n",
    "    'load_model_path': 'Results_Classification\\RODNet_Occp_Classification\\Fold_1\\RODNet_Occp_Classification_fold_1.pt',  # specify path of pretrained model wieghts or set to False to train from scratch\n",
    "    'model_to_load': 'RODNet',  # choose one of the following models: 'CNN_1' 'CNN_2' 'CNN_2' 'CNN_3' 'SelfResNet18' 'ResNet'\n",
    "    'model_name': 'RODNet_Occp_Classification',  # choose a unique name for result folder\n",
    "    'aux_logits': False,  # Required for models with auxilliary outputs (e.g., InceptionV3)  \n",
    "    'fold_start': 1,  # The starting fold for training\n",
    "    'fold_last': 1,  # The last fold for training\n",
    "    'results_path': 'Results_Classification',  # main results folder\n",
    "}\n",
    "\n",
    "# SAVE CONFIG FILE\n",
    "with open(r\"Config_Train.ini\", 'w') as configfileObj:\n",
    "    config_file.write(configfileObj)\n",
    "    configfileObj.flush()\n",
    "    configfileObj.close()\n",
    "\n",
    "print(\"Config file 'Config_Train.ini' created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWQQ-U2bJ2Js"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSLqe-8gJ2R8"
   },
   "outputs": [],
   "source": [
    "%run -i Train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file 'Config_Test.ini' created\n"
     ]
    }
   ],
   "source": [
    "# CREATE OBJECT\n",
    "config_file = configparser.ConfigParser()\n",
    "# ADD NEW SECTION AND SETTINGS\n",
    "config_file[\"TEST\"] = {\n",
    "    'parentdir': '',  # Root or Parent Directory\n",
    "    'datafile': 'Data',  # Folder containing the dataset\n",
    "    'batch_size': 1,  # Batch Size, Change to fit hardware\n",
    "    'lossType': 'SoftM_MSE',  # loss function: 'SoftM_CELoss' or 'SoftM_MSE' or 'MSE'\n",
    "    'num_folds': 1,  # number of cross validation folds\n",
    "    'CI': 0.9,  # Confidence interval (missied cases with probability>=CI will be reported in excel file)\n",
    "    'load_model': False,  # specify path of pretrained model wieghts or set to False to train from scratch\n",
    "    'load_model_path': 'Results_Classification\\RODNet_Occp_Classification\\Fold_1\\RODNet_Occp_Classification_fold_1.pt',  # specify path of pretrained model wieghts or set to False to train from scratch\n",
    "    'labeled_data': True,  # set to true if you have the labeled test set\n",
    "    'model_name': 'RODNet_Occp_Classification',  # name of the saved model\n",
    "    'aux_logits': False,  # Required for models with auxilliary outputs (e.g., InceptionV3)  \n",
    "    'fold_start': 1,  # The starting fold for training\n",
    "    'fold_last': 1,  # The last fold for training\n",
    "    'N_steps': 1000,  # The last fold for training\n",
    "    'results_path': 'Results_Classification',  # main results folder\n",
    "}\n",
    "# SAVE CONFIG FILE\n",
    "with open(r\"Config_Test.ini\", 'w') as configfileObj:\n",
    "    config_file.write(configfileObj)\n",
    "    configfileObj.flush()\n",
    "    configfileObj.close()\n",
    "print(\"Config file 'Config_Test.ini' created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i Test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "tgW7r0C9TuZk",
    "Kir80l1FKPXB",
    "vMHdM26iekBm",
    "VUciLEJeyvyN",
    "WesN7p7AeYK4"
   ],
   "machine_shape": "hm",
   "name": "1D_CNN_Segmentation_End2End_Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
